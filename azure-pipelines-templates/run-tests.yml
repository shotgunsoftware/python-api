# This is the list of parameters for this template and the default values.
parameters:
  name: ''
  vm_image: ''

jobs:
  # The test will be named after the OS and Azure will suffix the strategy to make it unique
  # so we'll have a job name "Windows Python27" for example.
- job: ${{ parameters.name }}
  pool: 
    vmImage: ${{ parameters.vm_image }}
  strategy:
    # We support these two versions of Python.
    matrix:
      Python27:
        python.version: '2.7'
      Python37:
        python.version: '3.7'

  # The above strategy is another way of removing repetition. It will create one job per entry in the
  # matrix and insert those steps inside it. Jobs are run in parallel, steps are run sequentially
  # withing jobs. There are also stages, which allow you to run a groups of jobs sequentially,
  # but we're not using it here.
  steps:
  # Specify which version of Python we want to use. We'll pull it from the strategy matrix.
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '$(python.version)'
      addToPath: True

  # Install all dependencies needed for running the tests.
  - script: |
      python -m pip install --upgrade pip setuptools wheel
      python -m pip install -r tests/ci_requirements.txt
    displayName: Install tools

  # On Windows, we need to update the certificates, the cert store is missing the newer one
  # from Amazon like some clients experienced a while back. Who would have thought Microsoft
  # would have been out of date! ;)
  - ${{ if eq(parameters.name, 'Windows') }}:
    - powershell: |
        $cert_url = "https://www.amazontrust.com/repository/SFSRootCAG2.cer"
        $cert_file = New-TemporaryFile
        Invoke-WebRequest -Uri $cert_url -UseBasicParsing -OutFile $cert_file.FullName
        Import-Certificate -FilePath $cert_file.FullName -CertStoreLocation Cert:\LocalMachine\Root
      displayName: Updating OS Certificates

  # Run the tests and generate test coverage. The tests results are uploaded to Azure Pipelines in the
  # Tests tab of the build and each test run will be named after the --test-run-title argument to pytest,
  # for example 'Windows - 2.7'
  - bash: |
      cp ./tests/example_config ./tests/config
      pytest -v --cov shotgun_api3 --cov-report xml --test-run-title="${{parameters.name}}-$(python.version)"
    displayName: Running tests
    env:
      # Pass the values needed to authenticate with the Shotgun site and create some entities.
      # Those values are all encrypted in the build system and are not shared with
      # pull requests from clients.
      # When those environment variables are not set, any tests that require a Shotgun connection,
      # which is like 95% of them, will be skipped.
      SG_SERVER_URL: $(ci_site)
      SG_SCRIPT_NAME: $(ci_site_script_name)
      SG_API_KEY: $(ci_site_script_key)
      # The unit tests manipulate the user and project during the tests, which can cause collisions,
      # so sandbox each build variant.
      # This will give a user login like 'something-macOS-2.7'
      SG_HUMAN_LOGIN: $(python_api_human_login)-${{parameters.name}}-$(python.version)
      # This will give a user name like 'something macOS 2.7'
      SG_HUMAN_NAME: $(python_api_human_name) ${{parameters.name}} $(python.version)
      SG_HUMAN_PASSWORD: $(python_api_human_password)
      # This will give a project name like 'Python API CI - macOS - 2.7'
      SG_PROJECT_NAME: ${{ format('Python API CI - {0}', parameters.name) }} - $(python.version)

  # Upload the code coverage result to codecov.io.
  - script: |
      bash <(curl https://codecov.io/bash) -t $(python_api_codecov_token) -f coverage.xml -F adder -F subtractor
    displayName: 'Uploading code coverage to codecov'
